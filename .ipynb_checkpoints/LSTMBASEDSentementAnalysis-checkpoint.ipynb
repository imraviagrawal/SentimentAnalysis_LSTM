{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great! You have 12500 pos reviews in ../large_movie_review_dataset/train/pos\n",
      "Great! You have 12500 neg reviews in ../large_movie_review_dataset/train/neg\n"
     ]
    }
   ],
   "source": [
    "# download the IMDB large movie review corpus from the class webpage to a file location on your computer\n",
    "\n",
    "PATH_TO_DATA = '../large_movie_review_dataset'  # set this variable to point to the location of the IMDB corpus on your computer\n",
    "POS_LABEL = 'pos'\n",
    "NEG_LABEL = 'neg'\n",
    "TRAIN_DIR = os.path.join(PATH_TO_DATA, \"train\")\n",
    "TEST_DIR = os.path.join(PATH_TO_DATA, \"test\")\n",
    "\n",
    "for label in [POS_LABEL, NEG_LABEL]:\n",
    "    if len(os.listdir(TRAIN_DIR + \"/\" + label)) == 12500:\n",
    "        print \"Great! You have 12500 {} reviews in {}\".format(label, TRAIN_DIR + \"/\" + label)\n",
    "    else:\n",
    "        print \"Oh no! Something is wrong. Check your code which loads the reviews\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_doc_and_more(doc):\n",
    "    bow = defaultdict(float)\n",
    "    \n",
    "    # Converting into lower case text\n",
    "    doc_lower = doc.lower() \n",
    "    \n",
    "    # removing pucntuations (\"..\", \".\", \",\")\n",
    "    doc_wo_punc = re.sub(r'(\\.+$|\\?+$|\\,|\\'|\\.{2,}|<br *(/>)?)|-',\"\",doc_lower)\n",
    "    #doc_wo_punc = re.sub(r\"[^A-Za-z0-9 ]+\",\"\", doc_lower)\n",
    "    # removing two spaces \n",
    "    text_with_one_space = re.sub(r'[ ]{2,}',\" \", doc_wo_punc).split()\n",
    "    \n",
    "    # removing stop words like \"and\", \"the\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_sentence = [w for w in text_with_one_space if not w in stop_words]\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['looking', 'forward', 'guardian', 'walked', 'theater', 'wasnt', 'really', 'mood', 'particular', 'time.', 'kind', 'like', 'olive', 'garden', 'like', 'right', 'mindset', 'thoroughly', 'enjoy', 'it.im', 'exactly', 'sure', 'dampening', 'spirit']\n"
     ]
    }
   ],
   "source": [
    "print tokenize_doc_and_more(\"I was looking forward to The Guardian, but when I walked into the theater I wasn't really in the mood for it at that particular time. It's kind of like the Olive Garden - I like it, but I have to be in the right mindset to thoroughly enjoy it.<br /><br />I'm not exactly sure what was dampening my spirit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reading dataset and making list of list for positive and negative training examples.\n",
    "positiveSentence = []\n",
    "negativeSentence = []\n",
    "numberofWords = []\n",
    "for label in [POS_LABEL, NEG_LABEL]:\n",
    "    for directory in [TRAIN_DIR, TEST_DIR]:\n",
    "        for fn in glob.glob(directory + \"/\" + label + \"/*txt\"):\n",
    "            ## Implement me!\n",
    "            temp = tokenize_doc_and_more(open(fn).read())\n",
    "            numberofWords.append(len(temp))\n",
    "            if label == POS_LABEL:\n",
    "                positiveSentence.append(temp)\n",
    "            else:\n",
    "                negativeSentence.append(temp)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of positive examples 25000\n",
      "The number of negative examples 25000\n"
     ]
    }
   ],
   "source": [
    "#Check the loaded data in the positive and negative sentence\n",
    "print \"The number of positive examples \" + str(len(positiveSentence))\n",
    "print \"The number of negative examples \" + str(len(negativeSentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEKCAYAAADenhiQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4lgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4d71c87d10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Printing the number of words in all the sentences\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(numberofWords, 50)\n",
    "plt.xlabel('Sequence Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axis([0, 1200, 0, 8000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum length of words is about 600, but most sentence are covered in 250 words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxSeqLength = 250\n",
    "batchSize = 24\n",
    "numDimensions = 50\n",
    "numFiles= 50000\n",
    "numClasses = 2\n",
    "lstmUnits = 64\n",
    "iterations = 100000\n",
    "keep_prob = 0.75"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Loading the word vector \n",
    "filename = 'glove.6B.50d.txt'\n",
    "def loadGloVe(filename):\n",
    "    vocab = {}\n",
    "    embd = []\n",
    "    index = 0\n",
    "    file = open(filename,'r')\n",
    "    for line in file.readlines():\n",
    "        row = line.strip().split(' ')\n",
    "        vocab[row[0]] = index\n",
    "        embd.append(row[1:])\n",
    "        index += 1\n",
    "    print('Loaded GloVe!')\n",
    "    file.close()\n",
    "    return vocab,embd\n",
    "\n",
    "# Glove Vector location\n",
    "fileName = \"../glove.6B/glove.6B.50d.txt\"\n",
    "wordList, embdd = loadGloVe(fileName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordVector = np.load('wordVectors.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n"
     ]
    }
   ],
   "source": [
    "# Number of words in the the word vector \n",
    "print len(list(wordVector))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Ids Matrix Conversion"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# ids = np.zeros((numFiles, maxSeqLength), dtype='int32')\n",
    "fileCounter = 0\n",
    "for sentence in positiveSentence:\n",
    "    indexCounter = 0 \n",
    "    for word in sentence:\n",
    "        ids[fileCounter][indexCounter] = wordList[word] if word in wordList else 399999 #Vector for unkown words\n",
    "        indexCounter = indexCounter + 1\n",
    "        if indexCounter >= maxSeqLength:\n",
    "            break\n",
    "    fileCounter = fileCounter + 1 \n",
    "\n",
    "for sentence in negativeSentence:\n",
    "    indexCounter = 0 \n",
    "    for word in sentence:\n",
    "        ids[fileCounter][indexCounter] = wordList[word] if word in wordList else 399999 #Vector for unkown words\n",
    "        indexCounter = indexCounter + 1\n",
    "        if indexCounter >= maxSeqLength:\n",
    "            break\n",
    "    fileCounter = fileCounter + 1\n",
    "#np.save('idsMatrix', ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Traning and Testing Batch \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initializing input label and respective embedding matrix\n",
    "label = tf.placeholder(tf.float32, [batchSize, numClasses])\n",
    "input_data = tf.placeholder(tf.int32, [batchSize, maxSeqLength])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating the data variable and performing lookup function\n",
    "data = tf.Variable(tf.zeros([batchSize, maxSeqLength, numDimensions], tf.float32))\n",
    "data = tf.nn.embedding_lookup(wordVector, input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing the model\n",
    "Now that we have the data in the format that we want, let’s look at how we can feed this input into an LSTM network. We’re going to call the tf.nn.rnn_cell.BasicLSTMCell function. This function takes in an integer for the number of LSTM units that we want. This is one of the hyperparameters that will take some tuning to figure out the optimal value. We’ll then wrap that LSTM cell in a dropout layer to help prevent the network from overfitting.\n",
    "\n",
    "\n",
    "Finally, we’ll feed both the LSTM cell and the 3-D tensor full of input data into a function called tf.nn.dynamic_rnn. This function is in charge of unrolling the whole network and creating a pathway for the data to flow through the RNN graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstmCell = tf.contrib.rnn.BasicLSTMCell(lstmUnits)\n",
    "lstmCell = tf.contrib.rnn.DropoutWrapper(cell = lstmcell, input_keep_prob= keep_probss)\n",
    "value, _ = tf.nn.dynamic_rnn(lstmCell, data, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight = tf.Variable(tf.truncated_normal([lstmUnits, numClasses]))\n",
    "bias = tf.Variable(tf.constant(0.1, shape=[numClasses]))\n",
    "value = tf.transpose(value, [1, 0, 2])\n",
    "last = tf.gather(value, int(value.get_shape()[0]) - 1)\n",
    "prediction = (tf.matmul(last, weight) + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correctPred = tf.equal(tf.argmax(prediction,1), tf.argmax(labels,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=labels))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "tf.summary.scalar('Loss', loss)\n",
    "tf.summary.scalar('Accuracy', accuracy)\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
