{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great! You have 12500 pos reviews in ../large_movie_review_dataset/train/pos\n",
      "Great! You have 12500 neg reviews in ../large_movie_review_dataset/train/neg\n"
     ]
    }
   ],
   "source": [
    "# download the IMDB large movie review corpus from the class webpage to a file location on your computer\n",
    "\n",
    "PATH_TO_DATA = '../large_movie_review_dataset'  # set this variable to point to the location of the IMDB corpus on your computer\n",
    "POS_LABEL = 'pos'\n",
    "NEG_LABEL = 'neg'\n",
    "TRAIN_DIR = os.path.join(PATH_TO_DATA, \"train\")\n",
    "TEST_DIR = os.path.join(PATH_TO_DATA, \"test\")\n",
    "\n",
    "for label in [POS_LABEL, NEG_LABEL]:\n",
    "    if len(os.listdir(TRAIN_DIR + \"/\" + label)) == 12500:\n",
    "        print \"Great! You have 12500 {} reviews in {}\".format(label, TRAIN_DIR + \"/\" + label)\n",
    "    else:\n",
    "        print \"Oh no! Something is wrong. Check your code which loads the reviews\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_doc_and_more(doc):\n",
    "    bow = defaultdict(float)\n",
    "    \n",
    "    # Converting into lower case text\n",
    "    doc_lower = doc.lower() \n",
    "    \n",
    "    # removing pucntuations (\"..\", \".\", \",\")\n",
    "    doc_wo_punc = re.sub(r'(\\.+$|\\?+$|\\,|\\'|\\.{2,}|<br *(/>)?)|-',\"\",doc_lower)\n",
    "    #doc_wo_punc = re.sub(r\"[^A-Za-z0-9 ]+\",\"\", doc_lower)\n",
    "    # removing two spaces \n",
    "    text_with_one_space = re.sub(r'[ ]{2,}',\" \", doc_wo_punc).split()\n",
    "    \n",
    "    # removing stop words like \"and\", \"the\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_sentence = [w for w in text_with_one_space if not w in stop_words]\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['looking', 'forward', 'guardian', 'walked', 'theater', 'wasnt', 'really', 'mood', 'particular', 'time.', 'kind', 'like', 'olive', 'garden', 'like', 'right', 'mindset', 'thoroughly', 'enjoy', 'it.im', 'exactly', 'sure', 'dampening', 'spirit']\n"
     ]
    }
   ],
   "source": [
    "print tokenize_doc_and_more(\"I was looking forward to The Guardian, but when I walked into the theater I wasn't really in the mood for it at that particular time. It's kind of like the Olive Garden - I like it, but I have to be in the right mindset to thoroughly enjoy it.<br /><br />I'm not exactly sure what was dampening my spirit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reading dataset and making list of list for positive and negative training examples.\n",
    "positiveSentence = []\n",
    "negativeSentence = []\n",
    "numberofWords = []\n",
    "for label in [POS_LABEL, NEG_LABEL]:\n",
    "    for directory in [TRAIN_DIR, TEST_DIR]:\n",
    "        for fn in glob.glob(directory + \"/\" + label + \"/*txt\"):\n",
    "            ## Implement me!\n",
    "            temp = tokenize_doc_and_more(open(fn).read())\n",
    "            numberofWords.append(len(temp))\n",
    "            if label == POS_LABEL:\n",
    "                positiveSentence.append(temp)\n",
    "            else:\n",
    "                negativeSentence.append(temp)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of positive examples 25000\n",
      "The number of negative examples 25000\n"
     ]
    }
   ],
   "source": [
    "#Check the loaded data in the positive and negative sentence\n",
    "print \"The number of positive examples \" + str(len(positiveSentence))\n",
    "print \"The number of negative examples \" + str(len(negativeSentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEKCAYAAADenhiQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4lgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7b1bec7310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Printing the number of words in all the sentences\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(numberofWords, 50)\n",
    "plt.xlabel('Sequence Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axis([0, 1200, 0, 8000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum length of words is about 600, but most sentence are covered in 250 words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxSeqLength = 250\n",
    "batchSize = 1\n",
    "numDimensions = 50\n",
    "numFiles= 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded GloVe!\n"
     ]
    }
   ],
   "source": [
    "# Loading the word vector \n",
    "\n",
    "import numpy as np\n",
    "filename = 'glove.6B.50d.txt'\n",
    "def loadGloVe(filename):\n",
    "    vocab = []\n",
    "    embd = []\n",
    "    file = open(filename,'r')\n",
    "    for line in file.readlines():\n",
    "        row = line.strip().split(' ')\n",
    "        vocab.append(row[0])\n",
    "        embd.append(row[1:])\n",
    "    print('Loaded GloVe!')\n",
    "    file.close()\n",
    "    return vocab,embd\n",
    "\n",
    "# Glove Vector location\n",
    "fileName = \"../glove.6B/glove.6B.50d.txt\"\n",
    "wordList, wordVector = loadGloVe(fileName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordVector = np.load('wordVectors.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n"
     ]
    }
   ],
   "source": [
    "# Number of words in the the word vector \n",
    "print len(list(wordVector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "firstfile = np.zeros((maxSeqLength), dtype=\"int32\")\n",
    "indexCounter = 0\n",
    "for word in positiveSentence[0]:\n",
    "    try:\n",
    "        firstfile[indexCounter] = wordList.index(word)\n",
    "    except:\n",
    "        firstfile[indexCounter] = 399999\n",
    "    indexCounter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Id Matrix Commented because of computation of this code\n",
    "\n",
    "ids = np.zeros((numFiles, maxSeqLength), dtype='int32')\n",
    "fileCounter = 0\n",
    "for sentence in positiveSentence:\n",
    "    indexCounter = 0 \n",
    "    for word in sentence:\n",
    "        try:\n",
    "            ids[fileCounter][indexCounter] = wordList.index(word)\n",
    "        except ValueError:\n",
    "            ids[fileCounter][indexCounter] = 399999 #Vector for unkown words\n",
    "        indexCounter = indexCounter + 1\n",
    "        if indexCounter >= maxSeqLength:\n",
    "            break\n",
    "    fileCounter = fileCounter + 1 \n",
    "\n",
    "for sentence in negativeSentence:\n",
    "    indexCounter = 0 \n",
    "    for word in sentence:\n",
    "        try:\n",
    "            ids[fileCounter][indexCounter] = wordList.index(word)\n",
    "        except ValueError:\n",
    "            ids[fileCounter][indexCounter] = 399999 #Vector for unkown words\n",
    "        indexCounter = indexCounter + 1\n",
    "        if indexCounter >= maxSeqLength:\n",
    "            break\n",
    "    fileCounter = fileCounter + 1\n",
    "np.save('idsMatrix', ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the id matrix\n",
    "ids = np.load(\"idsMatrix.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "List of Tensors when single Tensor expected",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-8063e49812eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0midsTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_lookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordVector\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ravi/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.pyc\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0mtensor_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[0;32m--> 165\u001b[0;31m       tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    166\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m/home/ravi/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.pyc\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    365\u001b[0m       \u001b[0mnparray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m       \u001b[0m_AssertCompatible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m       \u001b[0mnparray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m       \u001b[0;31m# check to them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ravi/anaconda3/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.pyc\u001b[0m in \u001b[0;36m_AssertCompatible\u001b[0;34m(values, dtype)\u001b[0m\n\u001b[1;32m    297\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmismatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"List of Tensors when single Tensor expected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m       raise TypeError(\"Expected %s, got %s of type '%s' instead.\" %\n",
      "\u001b[0;31mTypeError\u001b[0m: List of Tensors when single Tensor expected"
     ]
    }
   ],
   "source": [
    "idsTensor = tf.constant(ids[0])\n",
    "with tf.Session() as sess:\n",
    "    print(tf.nn.embedding_lookup(wordVector,ids[0]).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
